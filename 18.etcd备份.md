#### etcd备份

etcd作为整个kubernetes的数据存储中心，存储了集群所有的数据信息，如果集群中发生了不可逆的事情只能从备份中恢复或者重建整个k8s集群



#### etcd一些查询操作

查看集群状态

```yaml
[root@test242 etcd]# ETCDCTL_API=3 etcdctl --cacert=/etc/etcd/pki/ca.crt --cert=/etc/etcd/pki/peer.crt --key=/etc/etcd/pki/peer.key --endpoints=https://192.168.3.242:2379,https://192.168.3.243:2379,https://192.168.3.244:2379 endpoint health
https://192.168.3.242:2379 is healthy: successfully committed proposal: took = 2.665491ms
https://192.168.3.243:2379 is healthy: successfully committed proposal: took = 2.363018ms
https://192.168.3.244:2379 is healthy: successfully committed proposal: took = 3.243417ms
```

获取key信息

```yaml
[root@test242 etcd]# ETCDCTL_API=3 etcdctl --cacert=/etc/etcd/pki/ca.crt --cert=/etc/etcd/pki/peer.crt --key=/etc/etcd/pki/peer.key --endpoints=https://192.168.3.242:2379,https://192.168.3.243:2379,https://192.168.3.244:2379 get /registry/apiregistration.k8s.io/apiservices/v1.apps 
/registry/apiregistration.k8s.io/apiservices/v1.apps
{"kind":"APIService","apiVersion":"apiregistration.k8s.io/v1beta1","metadata":{"name":"v1.apps","uid":"e10c7f50-49cc-11ea-a47a-0050569c4cad","creationTimestamp":"2020-02-07T17:11:28Z","labels":{"kube-aggregator.kubernetes.io/automanaged":"onstart"}},"spec":{"service":null,"group":"apps","version":"v1","groupPriorityMinimum":17800,"versionPriority":15},"status":{"conditions":[{"type":"Available","status":"True","lastTransitionTime":"2020-02-07T17:11:28Z","reason":"Local","message":"Local APIServices are always available"}]}}
```



#### 备份环境

| 主机    | IP            |
| ------- | ------------- |
| test242 | 192.168.3.242 |
| test243 | 192.168.3.243 |
| test244 | 192.168.3.244 |

etcd备份操作使用napshotsave，每次备份一个节点

```yaml
ETCDCTL_API=3 etcdctl --cacert=/etc/etcd/pki/ca.crt --cert=/etc/etcd/pki/peer.crt --key=/etc/etcd/pki/peer.key --endpoints=https://192.168.3.242:2379,https://192.168.3.243:2379,https://192.168.3.244:2379 snapshot save /data/etcd/etcd-snapshot-`date +%Y%m%d`.db
```



#### 恢复集群

停止所有的kube-apiserver服务

```
$ systemctl stop kube-apiserver
```



停止所有的etcd服务

```
$ systemctl stop etcd
```



删除原有的etcd目录下的数据

```
mv k8s.etcd /tmp/
```



```yaml
在etcd01执行
ETCDCTL_API=3 etcdctl snapshot restore /var/lib/etcd/etcd-snapshot-20200218.db   --name etcd01   --initial-cluster "etcd01=https://192.168.3.242:2380,etcd02=https://192.168.3.243:2380,etcd03=https://192.168.3.244:2380"   --initial-cluster-token etcd-cluster   --initial-advertise-peer-urls https://192.168.3.242:2380 --data-dir=/var/lib/etcd/k8s.etcd

chown -R etcd.etcd /var/lib/etcd/

在etcd02执行
ETCDCTL_API=3 etcdctl snapshot restore /var/lib/etcd/etcd-snapshot-20200218.db   --name etcd02   --initial-cluster "etcd01=https://192.168.3.242:2380,etcd02=https://192.168.3.243:2380,etcd03=https://192.168.3.244:2380"   --initial-cluster-token etcd-cluster   --initial-advertise-peer-urls https://192.168.3.243:2380 --data-dir=/var/lib/etcd/k8s.etcd

chown -R etcd.etcd /var/lib/etcd/

在etcd03执行
ETCDCTL_API=3 etcdctl snapshot restore /var/lib/etcd/etcd-snapshot-20200218.db   --name etcd03   --initial-cluster "etcd01=https://192.168.3.242:2380,etcd02=https://192.168.3.243:2380,etcd03=https://192.168.3.244:2380"   --initial-cluster-token etcd-cluster   --initial-advertise-peer-urls https://192.168.3.244:2380 --data-dir=/var/lib/etcd/k8s.etcd

chown -R etcd.etcd /var/lib/etcd/

```



##### etcd恢复完成后，开启整个etcd服务

```yaml
$ systemctl start etcd
```



#####  3台etcd启动完成，检查etcd集群状态 

```yaml
[root@test242 etcd]# ETCDCTL_API=3 etcdctl --cacert=/etc/etcd/pki/ca.crt --cert=/etc/etcd/pki/peer.crt --key=/etc/etcd/pki/peer.key --endpoints=https://192.168.3.242:2379,https://192.168.3.243:2379,https://192.168.3.244:2379 endpoint health
```



##### 等etcd集群正常后恢复api-server

```
$ systemctl start kube-apiserver
```



##### 检查集群是否正常

```yaml
$ kubectl describe cs
```



##### 整个恢复顺序

停止kube-apiserver --> 停止etcd --> 恢复数据 --> 启动etcd --> 启动kube-apiserver (只需备份一台etcd数据)